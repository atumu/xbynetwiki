title: elasticsearch入门3 

#  Elasticsearch入门之分布式增删改查 
这一章我们深入这些内部细节来帮助你更好的理解数据是如何在分布式系统中存储的。下面的信息只是出于兴趣阅读，你不必为了使用Elasticsearch而弄懂和记住所有的细节。讨论的这些选项只提供给高级用户。

##  路由文档到分片 
当你索引一个文档，它被存储在单独一个主分片上。Elasticsearch是如何知道文档属于哪个分片的呢？当你创建一个新文档，它是如何知道是应该存储在分片1还是分片2上的呢？
进程不能是随机的，因为我们将来要检索文档。事实上，它根据一个简单的算法决定：
shard = hash(routing) % number_of_primary_shards
routing值是一个任意字符串，它默认是_id但也可以自定义。这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量得到一个**余数(remainder)**，余数的范围永远是0到number_of_primary_shards - 1，这个数字就是特定文档所在的分片。

这也解释了为什么**主分片的数量只能在创建索引时定义且不能修改：如果主分片的数量在未来改变了，所有先前的路由值就失效了，文档也就永远找不到了。**

有时用户认为固定数量的主分片会让之后的扩展变得很困难。现实中，有些技术会在你需要的时候让扩展变得容易。我们将在《扩展》章节讨论。
所有的文档API（get、index、delete、bulk、update、mget）都接收一个**routing参数**，它用来自定义文档到分片的映射。**自定义路由值可以确保所有相关文档——例如属于同一个人的文档——被保存在同一分片上**。我们将在《扩展》章节说明你为什么需要这么做。

##  主分片和复制分片如何交互 
为了阐述意图，我们假设有三个节点的集群。它包含一个叫做bblogs的索引并拥有两个主分片。每个主分片有两个复制分片。相同的分片不会放在同一个节点上，所以我们的集群是这样的：
有三个节点一个索引的集群
![](/data/dokuwiki/search/pasted/20160108-110656.png)
我们能够发送请求给集群中任意一个节点。**每个节点都有能力处理任意请求。每个节点都知道任意文档所在的节点，所以也可以将请求转发到需要的节点**。下面的例子中，我们将发送所有请求给Node 1，这个节点我们将会称之为**请求节点(requesting node)**
提示：
当我们发送请求，最好的做法是循环通过所有节点请求，这样可以平衡负载。

##  新建、索引和删除文档 
新建、索引和删除请求都是**写(write)**操作，它们必须在` 主分片 `上成功完成才能复制到相关的复制分片上。
![](/data/dokuwiki/search/pasted/20160108-153044.png)
下面我们罗列在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤：

客户端给Node 1发送新建、索引或删除请求。
  * 节点使用文档的_id确定文档属于分片0。它转发请求到Node 3，分片0位于这个节点上。
  * Node 3在主分片上执行请求，如果成功，它转发请求到相应的位于Node 1和Node 2的复制节点上。当所有的复制节点报告成功，Node 3报告成功到请求的节点，请求的节点再报告给客户端。
  * **客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。你的修改生效了。**
有很多可选的请求参数允许你更改这一过程。你可能想牺牲一些安全来提高性能。这一选项很少使用因为Elasticsearch已经足够快。

##  检索文档 
文档能够从主分片或任意一个复制分片被检索。
![](/data/dokuwiki/search/pasted/20160108-153329.png)
下面我们罗列在主分片或复制分片上检索一个文档必要的顺序步骤：

客户端给Node 1发送get请求。
  * 节点使用文档的_id确定文档属于分片0。分片0对应的复制分片在三个节点上都有。此时，它转发请求到Node 2。
  * Node 2返回endangered给Node 1然后返回给客户端。
**对于读请求，为了平衡负载，请求节点会为每个请求选择不同的分片——它会循环所有分片副本。**
可能的情况是，一个被索引的文档已经存在于主分片上却还没来得及同步到复制分片上。这时复制分片会报告文档未找到，主分片会成功返回文档。一旦索引请求成功返回给用户，文档则在主分片和复制分片都是可用的。

##  局部更新文档 
update API 结合了之前提到的读和写的模式。
![](/data/dokuwiki/search/pasted/20160108-153507.png)
下面我们罗列执行局部更新必要的顺序步骤：

客户端给Node 1发送更新请求。
  * 它转发请求到主分片所在节点Node 3。
  * Node 3从主分片检索出文档，修改_source字段的JSON，然后在主分片上重建索引。如果有其他进程修改了文档**，它以retry_on_conflict设置的次数重复步骤3**，都未成功则放弃。
  * 如果Node 3成功更新文档，它同时转发文档的新版本到Node 1和Node 2上的复制节点以重建索引。当所有复制节点报告成功，Node 3返回成功给请求节点，然后返回给客户端。
update API还接受《新建、索引和删除》章节提到的routing、replication、consistency和timout参数。

基于文档的复制
当主分片转发更改给复制分片时，并不是转发更新请求，**而是转发整个文档的新版本。记住这些修改转发到复制节点是异步的，它们并不能保证到达的顺序与发送相同,通过版本号解决了这一问题**。如果Elasticsearch转发的仅仅是修改请求，修改的顺序可能是错误的，那得到的就是个损坏的文档。

##  批量请求与多文档模式 
` mget和bulk ` API与单独的文档类似。差别是请求节点知道每个文档所在的分片。它把多文档请求拆成**每个分片**的对文档请求，然后转发每个参与的节点。
一旦接收到每个节点的应答，然后整理这些响应组合为一个单独的响应，最后返回给客户端。
![](/data/dokuwiki/search/pasted/20160108-153947.png)
下面我们将罗列通过一个mget请求检索多个文档的顺序步骤：
  * 客户端向Node 1发送mget请求。
  * Node 1为每个分片构建一个多条数据检索请求，然后转发到这些请求所需的主分片或复制分片上。当所有回复被接收，Node 1构建响应并返回给客户端。
routing 参数可以被docs中的每个文档设置。

![](/data/dokuwiki/search/pasted/20160108-154010.png)
下面我们将罗列使用一个bulk执行多个create、index、delete和update请求的顺序步骤：

  * 客户端向Node 1发送bulk请求。
  * Node 1为每个分片构建批量请求，然后转发到这些请求所需的主分片上。
  * 主分片一个接一个的按序执行操作。当一个操作执行完，主分片转发新文档（或者删除部分）给对应的复制节点，然后执行下一个操作。复制节点为报告所有操作完成，节点报告给请求节点，请求节点整理响应并返回给客户端。
bulk API还可以在最上层使用replication和consistency参数，routing参数则在每个请求的元数据中使用。

##  为什么bulk请求是奇怪的格式？ 
当我们在《批量》一章中学习了批量请求后，你可能会问：“为什么bulk API需要带换行符的奇怪格式，而不是像mget API一样使用JSON数组？”

为了回答这个问题，我们需要简单的介绍一下背景：

批量中每个引用的文档属于不同的主分片，每个分片可能被分布于集群中的某个节点上。这意味着批量中的每个**操作(action)**需要被转发到对应的分片和节点上。

如果每个单独的请求被包装到JSON数组中，那意味着我们需要：

解析JSON为数组（包括文档数据，可能非常大）
检查每个请求决定应该到哪个分片上
为每个分片创建一个请求的数组
序列化这些数组为内部传输格式
发送请求到每个分片
这可行，但需要大量的RAM来承载本质上相同的数据，还要创建更多的数据结构使得JVM花更多的时间执行垃圾回收。

` 取而代之的，Elasticsearch则是从网络缓冲区中一行一行的直接读取数据 `。它使用换行符识别和解析**action/metadata**行，以决定哪些分片来处理这个请求。

这些行请求直接转发到对应的分片上。这些没有冗余复制，没有多余的数据结构。整个请求过程使用最小的内存在进行。