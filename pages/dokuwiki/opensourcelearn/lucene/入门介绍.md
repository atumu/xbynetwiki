title: 入门介绍 

#  lucene:入门介绍 

#  背景知识介绍 
数据分类：
对于日常生活中的数据，我们可以大致分为如下三大类：结构化数据、非结构化数据、半结构化数据：
  * 结构化数据：指具有固定格式或有限长度的数据，如数据库行数据：存在数据库中，可以用二维表结构来逻辑表达实现的数据
  * 非结构化数据：指不定长度或者无固定格式的数据，如邮件、word文档、音频、超音频等
  * 半结构化数据：对于这种数据可以按照结构化数据来处理，也可以提取纯文本按照非结构化数据来处理，如xml数据

 对于非结构化数据采用索引检索又可以说是全文检索（Full-Text-Search），在索引过程中，我大致给它分成两大步骤：
  * 索引创建（Indexing）：将结构化数据或非结构化数据提取信息创建索引的过程，具体如下图左半部分所示：
  * 搜索索引（Search）根据用户的查询条件，检索已创建的索引，返回查询结果的过程，具体如参照下图右半部分所示：

![](/data/dokuwiki/opensourcelearn/pasted/20150512-182031.png)
索引是什么？：
![](/data/dokuwiki/opensourcelearn/pasted/20150512-182533.png)
#  概述： 

Lucene 是apache软件基金会一个开放源代码的全文检索引擎工具包，是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。
项目地址：https://lucene.apache.org/
你可以把索引想象成这样一种数据结构，他能够使你快速的随机访问存储在索引中的关键词，进而找到该关键词所关联的文档。**Lucene 采用的是一种称为反向索引（inverted index）的机制。**反向索引就是说我们维护了一个词 / 短语表，对于这个表中的每个词 / 短语，都有一个链表描述了有哪些文档包含了这个词 / 短语。这样在用户输入查询条件的时候，就能非常快的得到搜索结果。由于 Lucene 提供了简单易用的 API，所以即使读者刚开始对全文本进行索引的机制并不太了解，也可以非常容易的使用 Lucene 对你的文档实现索引。
对文档建立好索引后，就可以在这些索引上面进行搜索了。搜索引擎首先会对搜索的关键词进行解析，然后再在建立好的索引上面进行查找，最终返回和用户输入的关键词相关联的文档。

对于中文用户来说，最关心的问题是其是否支持中文的全文检索。但通过后面对于Lucene的结构的介绍，你会了解到由于Lucene良好架构设计，**对中文的支持只需对其语言词法分析接口进行扩展就能实现对中文检索的支持**。
##  lucene的组成结构 
：对于外部应用来说索引模块(index)和检索模块(search)是主要的外部应用入口
org.apache.Lucene.search/	搜索入口,对在建立好的索引上进行搜索所需要的类。比如 ` IndexSearcher 和 Hits `, **IndexSearcher 定义了在指定的索引上进行搜索的方法，Hits 用来保存搜索得到的结果**。
org.apache.Lucene.index/	索引入口,协助创建索引以及对创建好的索引进行更新。这里面有两个基础的类：` IndexWriter 和 IndexReader `，其中 IndexWriter 是用来创建索引并添加文档到索引中的。
org.apache.Lucene.analysis/	语言分析器,对文档进行分词,因为文档在建立索引之前必须要进行分词
org.apache.Lucene.queryParser/	查询分析器
org.apache.Lucene.document/	存储结构
org.apache.Lucene.store/ 	底层IO/存储结构
org.apache.Lucene.util/	一些公用的数据结构
org.apache.lucene.document这个包提供了一些为封装要索引的文档所需要的类，比如 ` Document, Field `。这样，每一个文档最终被封装成了一个 Document 对象。

#  快速使用 
##  安装： 
官方文档：http://lucene.apache.org/core/4_6_0/core/overview-summary.html
Lucene版本：4.10.4
安装依赖包：很多，这里列举本系列会常用的。
  * lucene-core.jar 其中包括了常用的文档，索引，搜索，存储等相关核心代码。
  * lucene-queries-4.10.4.jar
  * lucene-queryparser-4.10.4.jar 提供了搜索相关的代码，用于各种搜索，比如模糊搜索，范围搜索，等等。
  * lucene-analyzers-common-4.10.4.jar 这里面包含了各种语言的词法分析器，用于对文件内容进行关键字切分，提取。
  * lucene-analyzers-smartcn-4.10.4.jar自带的扩展用于中文分词。
  * Lucene-highlighter-4.0.0.jar，这个jar包主要用于搜索出的内容高亮显示。
###  创建索引 
对于索引的创建，我对其总结出一个三步曲：需要检索的数据（Document）、分词技术（Analyzer）、索引组建（Indexer），可以简单的参照下图：
![](/data/dokuwiki/opensourcelearn/pasted/20150512-182225.png)
创建索引的过程如下：
为了对文档进行索引，Lucene 提供了五个基础的类，他们分别是`  Document, Field, IndexWriter, Analyzer, Directory。 `下面我们分别介绍一下这五个类的用途：
Document 
是用来描述文档的，这里的文档可以指一个 HTML 页面，一封电子邮件，或者是一个文本文件。**一个 Document 对象由多个 Field 对象组成的。**可以把一个 Document 对象想象成数据库中的一个记录，而每个 Field 对象就是记录的一个字段。

Field
**Field 对象是用来描述一个文档的某个属性的**，比如一封电子邮件的标题和内容可以用两个 Field 对象分别描述。

IndexWriter
IndexWriter 是 Lucene 用来创建索引的一个核心的类，他的作用是**把一个个的 Document 对象加到索引中来。**
Directory
**这个类代表了 Lucene 的索引的存储的位置**，这是一个抽象类，` 它目前有两个实现，第一个是 FSDirectory `，它表示一个存储在文件系统中的索引的位置。` 第二个是 RAMDirectory `，它表示一个存储在内存当中的索引的位置。


（1）、建立分词器Analyzer和索引器IndexWriter，这相当于一本书的框架
（2）、建立文档对象Document,这相当于一篇文章。

（3）、建立信息字段对象Field，这相当于一篇文章中的不同信息（标题、正文等）。
（4）、将Field添加到Document里面。
（5）、将Document添加到IndexWriter里面。

（6）、关闭索引器IndexWriter。
我们还是通过简单的例子来介绍这个过程
第一步数据：Document事例数据：
你好！我是小李。
中国在哪里？
你是谁？
lucene基础知识学习课程。
你在中石油上学？
中石油在哪里？

第二步：分词技术，这里采用StandarAnalyzer(标准分词)
你|好|我|是|小|李|
中|国|在|哪|里|
你|是|谁|
lucene|基|础|知|识|学|习|课|程|
你|在|中|石|油|上|学|
中|石|油|在|哪|里|
第三步：索引创建字典：
![](/data/dokuwiki/opensourcelearn/pasted/20150512-182437.png)
 第三步：索引组建合并词成倒排表：
![](/data/dokuwiki/opensourcelearn/pasted/20150512-182443.png)
 到现在，索引文件就已经创建完成。
**索引过程**：

索引过程中可以看到：
  * 语言分析器提供了抽象的接口，**因此语言分析(Analyser)是可以定制的**，虽然lucene缺省提供了2个比较通用的分析器**SimpleAnalyser和StandardAnalyser**，` 这2个分析器缺省都不支持中文，所以要加入对中文语言的切分规则，需要修改这2个分析器 `。` 常用的有StandardAnalyzer（标准分析器）、CJKAnalyzer（二分法分词器）、ChineseAnalyzer（中文分析器）等。 `
  * Lucene并没有规定数据源的格式，而只提供了一个通用的结构（Document对象）来接受索引的输入，因此输入的数据源可以是：数据库，WORD文档，PDF文档，HTML文档……**只要能够设计相应的解析转换器将数据源构造成成Docuement对象即可进行索引**。
  * 对于大批量的数据索引，还可以通过调整IndexerWrite的文件合并频率属性（mergeFactor）来提高批量索引的效率。


###  执行搜索： 
利用 Lucene 进行搜索就像建立索引一样也是非常方便的。在上面一部分中，我们已经为一个目录下的文本文档建立好了索引，现在我们就要在这个索引上进行搜索以找到包含某个关键词或短语的文档。
Lucene 提供了几个基础的类来完成这个过程，它们分别是呢 ` IndexSearcher, Term, Query, TermQuery, Hits `. 下面我们分别介绍这几个类的功能。
Query
这是一个抽象类，他有多个实现，比如 ` TermQuery, BooleanQuery, PrefixQuery. ` 这个类的目的是**把用户输入的查询字符串封装成 Lucene 能够识别的 Query。**
Term
**Term 是搜索的基本单位，一个 Term 对象有两个 String 类型的域组成。**生成一个 Term 对象可以有如下一条语句来完成：Term term = new Term(“fieldName”,”queryWord”); 其中第一个参数代表了要在文档的哪一个 Field 上进行查找，第二个参数代表了要查询的关键词。
TermQuery
TermQuery 是抽象类 Query 的一个子类，它同时也是 Lucene 支持的最为基本的一个查询类。生成一个 TermQuery 对象由如下语句完成： TermQuery termQuery = new TermQuery(new Term(“fieldName”,”queryWord”)); 它的构造函数只接受一个参数，那就是一个 Term 对象。
IndexSearcher
IndexSearcher 是用来在建立好的索引上进行搜索的**。它只能以只读的方式打开一个索引**，所以可以有多个 IndexSearcher 的实例在一个索引上进行操作。
Hits
**Hits 是用来保存搜索的结果的。**

对索引的检索过程，我对其总结出四步曲：**获取检索词（KeyWords）、分词技术（Analyzer）、检索索引（Aearch）、返回结果列表**，可以简单参照下图：
![](/data/dokuwiki/opensourcelearn/pasted/20150512-182625.png)
同样我们还是继续接上述事例去说搜索过程

第一步：KeyWord事例数据
中石油

第二步：分词技术（因为创建索引的时候，采用的是标准分词，索引在搜索的过程，也应该采用该分词技术）
中|石|油|
第三步：检索索引搜索记录：
![](/data/dokuwiki/opensourcelearn/pasted/20150512-182739.png)
第四步：返回结果列表
检索过程和结果显示：


在整个检索过程中，语言分析器，查询分析器，甚至搜索器（Searcher）都是提供了抽象的接口，可以根据需要进行定制。

建立一个关键字与文件的相关映射
![](/data/dokuwiki/opensourcelearn/lucene/pasted/20151224-110751.png)
有了这种映射关系，我们就来看看Lucene的架构设计。
![](/data/dokuwiki/opensourcelearn/lucene/pasted/20151224-110852.png)
我们可以看到，Lucene的使用主要体现在两个步骤：
　　1 **创建索引**，通过` IndexWriter `对不同的文件进行索引的创建，并将其保存在索引相关文件存储的位置中。
　　2 **通过索引查寻关键字相关文档**。
```

Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_CURRENT);

    // Store the index in memory:
    Directory directory = new RAMDirectory();
    // To store an index on disk, use this instead:
    //Directory directory = FSDirectory.open("/tmp/testindex");
    IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);
    IndexWriter iwriter = new IndexWriter(directory, config);
    Document doc = new Document();
    String text = "This is the text to be indexed.";
    doc.add(new Field("fieldname", text, TextField.TYPE_STORED));
    iwriter.addDocument(doc);
    iwriter.close();
    
    // Now search the index:
    DirectoryReader ireader = DirectoryReader.open(directory);
    IndexSearcher isearcher = new IndexSearcher(ireader);
    // Parse a simple query that searches for "text":
    QueryParser parser = new QueryParser(Version.LUCENE_CURRENT, "fieldname", analyzer);
    Query query = parser.parse("text");
    ScoreDoc[] hits = isearcher.search(query, null, 1000).scoreDocs;
    assertEquals(1, hits.length);
    // Iterate through the results:
    for (int i = 0; i < hits.length; i++) {
      Document hitDoc = isearcher.doc(hits[i].doc);
      assertEquals("This is the text to be indexed.", hitDoc.get("fieldname"));
    }
    ireader.close();
    directory.close();

```

##  索引的创建 
首先，我们需要定义一个**词法分析器**。
　　比如一句话，“我爱我们的中国！”，如何对他拆分，扣掉停顿词“的”，提取关键字“我”“我们”“中国”等等。这就要借助的` 词法分析器Analyzer `来实现。**这里面使用的是标准的词法分析器，如果专门针对汉语，还可以搭配paoding，进行使用。**
1 Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_CURRENT);
参数中的Version.LUCENE_CURRENT，代表使用当前的Lucene版本，本文环境中也可以写成Version.LUCENE_40。

第二步，确定索引文件存储的位置，Lucene提供给我们两种方式：
1 本地文件存储 
Directory directory = FSDirectory.open("/tmp/testindex");
2 内存存储
Directory directory = new RAMDirectory();
可以根据自己的需要进行设定。

第三步，创建` IndexWriter `，进行**索引文件的写入**。
IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);
IndexWriter iwriter = new IndexWriter(directory, config);
这里的IndexWriterConfig，据官方文档介绍，是对indexWriter的配置，其中包含了两个参数，第一个是目前的版本，第二个是词法分析器Analyzer。

第四步，内容提取，进行索引的存储。
Document doc = new Document();
String text = "This is the text to be indexed.";
doc.add(new Field("fieldname", text, TextField.TYPE_STORED));
iwriter.addDocument(doc);
iwriter.close();
第一行，申请了一个document对象，这个类似于数据库中的表中的一行。
第二行，是我们即将索引的字符串。
第三行，把字符串存储起来（因为设置了` TextField.TYPE_STORED `,如果不想存储，可以使用其他参数，详情参考官方文档），并存储“表明”为"fieldname".
第四行，把doc对象加入到索引创建中。
第五行，` 关闭IndexWriter,提交创建内容。 `
这就是索引创建的过程。

##  关键字查询： 
第一步，打开存储位置
DirectoryReader ireader = DirectoryReader.open(directory);
第二步，创建搜索器
IndexSearcher isearcher = new IndexSearcher(ireader);
第三步，类似SQL，进行关键字查询
```

QueryParser parser = new QueryParser(Version.LUCENE_CURRENT, "fieldname", analyzer);
Query query = parser.parse("text");
ScoreDoc[] hits = isearcher.search(query, null, 1000).scoreDocs;
assertEquals(1, hits.length);
for (int i = 0; i < hits.length; i++) {
    Document hitDoc = isearcher.doc(hits[i].doc);
    assertEquals("This is the text to be indexed.",hitDoc.get("fieldname"));
}

```
这里，我们创建了一个查询器，并设置其词法分析器，以及查询的为”fieldname“。**查询结果会返回一个集合，类似SQL的ResultSet，我们可以提取其中存储的内容。**
关于各种不同的查询方式，可以参考官方手册，或者推荐的PPT
''第四步，关闭查询器等。
ireader.close();
directory.close();''

##  示列 

最后，写了个简单的例子，可以对一个文件夹内的内容进行索引的创建，并根据关键字筛选文件，并读取其中的内容。
**创建索引：**
```

/**
     * 创建当前文件目录的索引
     * @param path 当前文件目录
     * @return 是否成功
     */
    public static boolean createIndex(String path){
        Date date1 = new Date();
        List<File> fileList = getFileList(path);
        for (File file : fileList) {
            content = "";
            //获取文件后缀
            String type = file.getName().substring(file.getName().lastIndexOf(".")+1);
            if("txt".equalsIgnoreCase(type)){
                
                content += txt2String(file);
            
            }else if("doc".equalsIgnoreCase(type)){
            
                content += doc2String(file);
            
            }else if("xls".equalsIgnoreCase(type)){
                
                content += xls2String(file);
                
            }
            
            System.out.println("name :"+file.getName());
            System.out.println("path :"+file.getPath());
//            System.out.println("content :"+content);
            System.out.println();
            
            
            try{
                analyzer = new StandardAnalyzer(Version.LUCENE_CURRENT);
                directory = FSDirectory.open(new File(INDEX_DIR));
    
                File indexFile = new File(INDEX_DIR);
                if (!indexFile.exists()) {
                    indexFile.mkdirs();
                }
                IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);
                indexWriter = new IndexWriter(directory, config);
                
                Document document = new Document();
                document.add(new TextField("filename", file.getName(), Store.YES));
                document.add(new TextField("content", content, Store.YES));
                document.add(new TextField("path", file.getPath(), Store.YES));
                indexWriter.addDocument(document);
                indexWriter.commit();
                closeWriter();
    
                
            }catch(Exception e){
                e.printStackTrace();
            }
            content = "";
        }
        Date date2 = new Date();
        System.out.println("创建索引-----耗时：" + (date2.getTime() - date1.getTime()) + "ms\n");
        return true;
    }

```
**进行查询：**
```

/**
     * 查找索引，返回符合条件的文件
     * @param text 查找的字符串
     * @return 符合条件的文件List
     */
    public static void searchIndex(String text){
        Date date1 = new Date();
        try{
            directory = FSDirectory.open(new File(INDEX_DIR));
            analyzer = new StandardAnalyzer(Version.LUCENE_CURRENT);
            DirectoryReader ireader = DirectoryReader.open(directory);
            IndexSearcher isearcher = new IndexSearcher(ireader);
    
            QueryParser parser = new QueryParser(Version.LUCENE_CURRENT, "content", analyzer);
            Query query = parser.parse(text);
            
            ScoreDoc[] hits = isearcher.search(query, null, 1000).scoreDocs;
        
            for (int i = 0; i < hits.length; i++) {
                Document hitDoc = isearcher.doc(hits[i].doc);
                System.out.println("____________________________");
                System.out.println(hitDoc.get("filename"));
                System.out.println(hitDoc.get("content"));
                System.out.println(hitDoc.get("path"));
                System.out.println("____________________________");
            }
            ireader.close();
            directory.close();
        }catch(Exception e){
            e.printStackTrace();
        }
        Date date2 = new Date();
        System.out.println("查看索引-----耗时：" + (date2.getTime() - date1.getTime()) + "ms\n");
    }

```

全部代码：
```

package test;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileReader;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;

import jxl.Cell;
import jxl.Sheet;
import jxl.Workbook;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.LongField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.document.Field.Store;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.Version;
import org.apache.poi.hwpf.HWPFDocument;
import org.apache.poi.hwpf.usermodel.Range;

/**
 * @author xinghl
 *
 */
public class IndexManager{
    private static IndexManager indexManager;
    private static String content="";
    
    private static String INDEX_DIR = "D:\\luceneIndex";
    private static String DATA_DIR = "D:\\luceneData";
    private static Analyzer analyzer = null;
    private static Directory directory = null;
    private static IndexWriter indexWriter = null;
    
    /**
     * 创建索引管理器
     * @return 返回索引管理器对象
     */
    public IndexManager getManager(){
        if(indexManager == null){
            this.indexManager = new IndexManager();
        }
        return indexManager;
    }
    /**
     * 创建当前文件目录的索引
     * @param path 当前文件目录
     * @return 是否成功
     */
    public static boolean createIndex(String path){
        Date date1 = new Date();
        List<File> fileList = getFileList(path);
        for (File file : fileList) {
            content = "";
            //获取文件后缀
            String type = file.getName().substring(file.getName().lastIndexOf(".")+1);
            if("txt".equalsIgnoreCase(type)){
                
                content += txt2String(file);
            
            }else if("doc".equalsIgnoreCase(type)){
            
                content += doc2String(file);
            
            }else if("xls".equalsIgnoreCase(type)){
                
                content += xls2String(file);
                
            }
            
            System.out.println("name :"+file.getName());
            System.out.println("path :"+file.getPath());
//            System.out.println("content :"+content);
            System.out.println();
            
            
            try{
                analyzer = new StandardAnalyzer(Version.LUCENE_CURRENT);
                directory = FSDirectory.open(new File(INDEX_DIR));
    
                File indexFile = new File(INDEX_DIR);
                if (!indexFile.exists()) {
                    indexFile.mkdirs();
                }
                IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);
                indexWriter = new IndexWriter(directory, config);
                
                Document document = new Document();
                document.add(new TextField("filename", file.getName(), Store.YES));
                document.add(new TextField("content", content, Store.YES));
                document.add(new TextField("path", file.getPath(), Store.YES));
                indexWriter.addDocument(document);
                indexWriter.commit();
                closeWriter();
    
                
            }catch(Exception e){
                e.printStackTrace();
            }
            content = "";
        }
        Date date2 = new Date();
        System.out.println("创建索引-----耗时：" + (date2.getTime() - date1.getTime()) + "ms\n");
        return true;
    }
    
    /**
     * 读取txt文件的内容
     * @param file 想要读取的文件对象
     * @return 返回文件内容
     */
    public static String txt2String(File file){
        String result = "";
        try{
            BufferedReader br = new BufferedReader(new FileReader(file));//构造一个BufferedReader类来读取文件
            String s = null;
            while((s = br.readLine())!=null){//使用readLine方法，一次读一行
                result = result + "\n" +s;
            }
            br.close();    
        }catch(Exception e){
            e.printStackTrace();
        }
        return result;
    }
    
    /**
     * 读取doc文件内容
     * @param file 想要读取的文件对象
     * @return 返回文件内容
     */
    public static String doc2String(File file){
        String result = "";
        try{
            FileInputStream fis = new FileInputStream(file);
            HWPFDocument doc = new HWPFDocument(fis);
            Range rang = doc.getRange();
            result += rang.text();
            fis.close();
        }catch(Exception e){
            e.printStackTrace();
        }
        return result;
    }
    
    /**
     * 读取xls文件内容
     * @param file 想要读取的文件对象
     * @return 返回文件内容
     */
    public static String xls2String(File file){
        String result = "";
        try{
            FileInputStream fis = new FileInputStream(file);   
            StringBuilder sb = new StringBuilder();   
            jxl.Workbook rwb = Workbook.getWorkbook(fis);   
            Sheet[] sheet = rwb.getSheets();   
            for (int i = 0; i < sheet.length; i++) {   
                Sheet rs = rwb.getSheet(i);   
                for (int j = 0; j < rs.getRows(); j++) {   
                   Cell[] cells = rs.getRow(j);   
                   for(int k=0;k<cells.length;k++)   
                   sb.append(cells[k].getContents());   
                }   
            }   
            fis.close();   
            result += sb.toString();
        }catch(Exception e){
            e.printStackTrace();
        }
        return result;
    }
    /**
     * 查找索引，返回符合条件的文件
     * @param text 查找的字符串
     * @return 符合条件的文件List
     */
    public static void searchIndex(String text){
        Date date1 = new Date();
        try{
            directory = FSDirectory.open(new File(INDEX_DIR));
            analyzer = new StandardAnalyzer(Version.LUCENE_CURRENT);
            DirectoryReader ireader = DirectoryReader.open(directory);
            IndexSearcher isearcher = new IndexSearcher(ireader);
    
            QueryParser parser = new QueryParser(Version.LUCENE_CURRENT, "content", analyzer);
            Query query = parser.parse(text);
            
            ScoreDoc[] hits = isearcher.search(query, null, 1000).scoreDocs;
        
            for (int i = 0; i < hits.length; i++) {
                Document hitDoc = isearcher.doc(hits[i].doc);
                System.out.println("____________________________");
                System.out.println(hitDoc.get("filename"));
                System.out.println(hitDoc.get("content"));
                System.out.println(hitDoc.get("path"));
                System.out.println("____________________________");
            }
            ireader.close();
            directory.close();
        }catch(Exception e){
            e.printStackTrace();
        }
        Date date2 = new Date();
        System.out.println("查看索引-----耗时：" + (date2.getTime() - date1.getTime()) + "ms\n");
    }
    /**
     * 过滤目录下的文件
     * @param dirPath 想要获取文件的目录
     * @return 返回文件list
     */
    public static List<File> getFileList(String dirPath) {
        File[] files = new File(dirPath).listFiles();
        List<File> fileList = new ArrayList<File>();
        for (File file : files) {
            if (isTxtFile(file.getName())) {
                fileList.add(file);
            }
        }
        return fileList;
    }
    /**
     * 判断是否为目标文件，目前支持txt xls doc格式
     * @param fileName 文件名称
     * @return 如果是文件类型满足过滤条件，返回true；否则返回false
     */
    public static boolean isTxtFile(String fileName) {
        if (fileName.lastIndexOf(".txt") > 0) {
            return true;
        }else if (fileName.lastIndexOf(".xls") > 0) {
            return true;
        }else if (fileName.lastIndexOf(".doc") > 0) {
            return true;
        }
        return false;
    }
    
    public static void closeWriter() throws Exception {
        if (indexWriter != null) {
            indexWriter.close();
        }
    }
    /**
     * 删除文件目录下的所有文件
     * @param file 要删除的文件目录
     * @return 如果成功，返回true.
     */
    public static boolean deleteDir(File file){
        if(file.isDirectory()){
            File[] files = file.listFiles();
            for(int i=0; i<files.length; i++){
                deleteDir(files[i]);
            }
        }
        file.delete();
        return true;
    }
    public static void main(String[] args){
        File fileIndex = new File(INDEX_DIR);
        if(deleteDir(fileIndex)){
            fileIndex.mkdir();
        }else{
            fileIndex.mkdir();
        }
        
        createIndex(DATA_DIR);
        searchIndex("man");
    }
}

```
可供参考：
http://blog.csdn.net/caohaicheng/article/details/35992149
http://blog.csdn.net/xiaojimanman/article/category/2841877
http://www.cnblogs.com/xing901022/p/3933675.html
http://www.chedong.com/tech/lucene.html